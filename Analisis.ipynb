{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a59be",
   "metadata": {},
   "source": [
    "# Apartat (C): Analitzant Dades\n",
    "\n",
    "1. Quin és el tipus de cada atribut? \n",
    "2. Quins atributs tenen una distribució Guassiana?\n",
    "3. Quin és l'atribut objectiu? Per què?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzarem només 3 decimals per mostra\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Funcio per a llegir dades en format csv\n",
    "def load_dataset(path):\n",
    "    dataset = pd.read_csv(path, header=0, delimiter=',')\n",
    "    return dataset\n",
    "\n",
    "# Carreguem dataset d'exemple\n",
    "dataset = load_dataset('Admission_Predict_Ver1.1.csv')\n",
    "data = dataset.values\n",
    "labels = dataset.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7e882",
   "metadata": {},
   "source": [
    "1. Quin és el tipus de cada atribut? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d71a13",
   "metadata": {},
   "source": [
    "<style>\n",
    "table {float:left}\n",
    "</style>\n",
    "\n",
    "| Atribut | Tipus de dada | Descripció |\n",
    "| :-- | :-: | :-- |\n",
    "|Serial No.|Nombre enter (int)| Posició de la entrada en ordre.|\n",
    "|GRE Score|Nombre enter (int)| Puntuació del estudiant a els Graduate Record Examinations, els valors van desde 260 fins a 340, representant el sistema de puntuació a India.|\n",
    "|TOEFL Score|Nombre enter (int)|Puntuació del estudiant a els Test Of English as a Foreign Language, els valors poden anar desde 0 fins a 120.|\n",
    "|University Rating|Nombre enter (int)| Puntuació de la universitat pot variar entre 1 i 5.|\n",
    "|SOP (Statement of Purpose)|Nombre Decimal (float)|Valoració de la qualitat del Statement of Purpose, en valors de 0 a 5 en intervals de 0’5.|\n",
    "|LOR (Letter of Recommendation)|Nombre Decimal (float)|Valoració de la qualitat del Letter of Recommendation, en valors de 0 a 5 en intervals de 0’5.|\n",
    "|CGPA (Undergraduate GPA)|Nombre Decimal (float)|Nota mitja de l'estudiant en els seus estudis undergrad. Va de 0 a 10.|\n",
    "|Research Experience|Booleà (bool)|Representa si l’estudiant ha tingut experiència de recerca anteriorment on no.|\n",
    "|Chance of Admission|Nombre Decimal (float)|Probabilitat de ser admès a la universitat donats tots els altres factors.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d61353",
   "metadata": {},
   "source": [
    "2. Quins atributs tenen una distribució Guassiana?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da074d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b58017",
   "metadata": {},
   "source": [
    "Els atributs que tenen una distribució gaussiana, basant en les grafiques son: GRE Score, TOEFL Score, University Rating, SOP, LOR, CGPA i Chance of Admission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328be52",
   "metadata": {},
   "source": [
    "3. Quin és l'atribut objectiu? Per què?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890db6f3",
   "metadata": {},
   "source": [
    "L’atribut objectiu és “Chance of Admission”, ja que tots els atributs anteriors contribueixen a l'obtenció d’aquest. A més, és el més rellevant de predir: un estudiant preuniversitari de l'Índia que conegués el seu expedient acadèmic i la valoració de la seva universitat de preferència, segurament estarà interessat a calcular les seves probabilitats de ser admès."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b50f6",
   "metadata": {},
   "source": [
    "# Apartat (B): Primeres regressions\n",
    "\n",
    "1. Quin són els atributs més importants per fer una bona predicció?\n",
    "\n",
    "2. Amb quin atribut s'assoleix un MSE menor?\n",
    "\n",
    "3. Quina correlació hi ha entre els atributs de la vostra base de dades?\n",
    "\n",
    "4. Com influeix la normalització en la regressió?\n",
    "\n",
    "5. Com millora la regressió quan es filtren aquells atributs de les mostres que no contenen informació?\n",
    "\n",
    "6. Si s'aplica un PCA, a quants components es redueix l'espai? Per què?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_split(size, precentatges):\n",
    "    assert(sum(precentatges) <= 1)\n",
    "    indices = np.arange(size)\n",
    "    split = np.zeros(size)\n",
    "    np.random.shuffle(indices)\n",
    "    used = 0\n",
    "    for i, p in enumerate(precentatges):\n",
    "        n = int(np.floor(size * p))\n",
    "        split[indices[used:n]] = i + 1\n",
    "        used += n\n",
    "    return split\n",
    "\n",
    "def perform_split(X, y, split):\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    for i in range(2):\n",
    "        X_.append(X[split == i])\n",
    "        y_.append(y[split == i])\n",
    "    return X_, y_\n",
    "    \n",
    "\n",
    "X = data[:, [i for i in range(8)]]\n",
    "y = data[:, 8]\n",
    "split_info = plan_split(X.shape[0], [.15, .15])\n",
    "\n",
    "X_, y_ = perform_split(X, y, split_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea343c72",
   "metadata": {},
   "source": [
    "1. Quin són els atributs més importants per fer una bona predicció?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524260d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "relacio = sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302187e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    sns.lmplot(x=labels[i], y=labels[8], data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f1fa3",
   "metadata": {},
   "source": [
    "Els millors són *GRE Score*, *TOEFL Score* i *CGPA*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ad210",
   "metadata": {},
   "source": [
    "2. Amb quin atribut s'assoleix un MSE menor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5671c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chartMe(content,colnames,rownames,precision=9,pre=\"\", extra=\"\"):\n",
    "    #Making the rows of the chart\n",
    "    chart=[]\n",
    "    for i,valuesRow in enumerate(content):\n",
    "        newRow=[str(pre+\" \"+rownames[i]+\" \"+extra)]\n",
    "        newRow.extend(valuesRow)\n",
    "        chart.append(newRow)\n",
    "        \n",
    "    #Setting up the precision, as requested by function call\n",
    "    pd.set_option('precision', precision)\n",
    "    seriousChart=pd.DataFrame(chart, columns=colnames).style.hide_index()\n",
    "    pd.reset_option('precision')\n",
    "    \n",
    "    return seriousChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartMe(content=['a','b','c'],colnames=['attribute','value'],rownames=['row 1','row 2','row 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adaf324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score as R2\n",
    "\n",
    "def regression(x, y):\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = LinearRegression()\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr\n",
    "\n",
    "def MSE(v1, v2):\n",
    "    return float(((v1 - v2)**2).mean())\n",
    "\n",
    "def calc_MSE(X, y):\n",
    "    mse = []\n",
    "    for i in range(X[0].shape[1]):\n",
    "        r = regression(X[0][:,[i]], y[0])\n",
    "        mse.append(MSE(r.predict(X[1][:,[i]]), y[1]))\n",
    "    return mse\n",
    "\n",
    "def calc_full(X, y):\n",
    "    r = regression(X[0], y[0])\n",
    "    pred = r.predict(X[1])\n",
    "    return (MSE(pred, y[1]), R2(pred, y[1]))\n",
    "\n",
    "def show_MSE(X, y, labels, extra=\"\"):\n",
    "    mse = calc_MSE(X, y)\n",
    "    for i, val in enumerate(mse):\n",
    "        print(\"MSE of \", labels[i], \" \", extra, \": \", val, sep=\"\")\n",
    "        \n",
    "def chart_MSE(X, y, labels, extra=\"\", pre=\"\"):\n",
    "    mse = calc_MSE(X, y)\n",
    "\n",
    "    chart=[]\n",
    "    for i, val in enumerate(mse):\n",
    "        newLineText=str(pre+\" \"+labels[i]+\" \"+extra)\n",
    "        chart.append([newLineText , val])\n",
    "    pd.options.display.float_format = \"{:,.9f}\".format\n",
    "    \n",
    "    chartDF=pd.DataFrame(chart, columns=[\"Atribute\",\"MSE\"]).style.hide_index()\n",
    "    return chartDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a74e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nL'atribut amb MSE menor és \", labels[mse.index(min(mse))], \".\")\n",
    "c=chart_MSE(X_, y_, labels)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319eebae",
   "metadata": {},
   "source": [
    "L'atribut amb MSE menor és  CGPA ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0969f",
   "metadata": {},
   "source": [
    "3. Quina correlació hi ha entre els atributs de la vostra base de dades?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fde322",
   "metadata": {},
   "source": [
    "Les correlacions entre els atributs de la nostra base de dades es poden visualitzar amb el següent heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacio = dataset.corr()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec5590",
   "metadata": {},
   "source": [
    "Com ja suposàvem, el primer atribut ('Serial No.') no té correlació amb cap altre, ja que només indica la posició de cada instància al dataset (exemple: la primera instància té 'Serial No.'=1, la segona en té 2, l'enèsima en té 'n'). Per tant, seria de sentit comú ignorar aquesta dada completament a l'hora de continuar analitzant.\n",
    "\n",
    "Per altra banda, les correlacions superiors o iguals al 75% són les següents:\n",
    "- GRE Score vs TOEFL Score (0.83)\n",
    "- GRE Score vs CGPA (0.83)\n",
    "- GRE Score vs Chance of Admit (0.81)\n",
    "- TOEFL vs CGPA (0.81)\n",
    "- TOEFL vs Chance of Admit (0.79)\n",
    "- CGPA vs Chance of Admit (0.88)\n",
    "\n",
    "Però, com que la variable objectiu és Chance of Admit, de la llista anterior només ens interessarem pels elements tercer, cinquè i sisè. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db989c15",
   "metadata": {},
   "source": [
    "4. Com influeix la normalització en la regressió?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa00b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalitzar(X):\n",
    "    mean = X.mean(0)\n",
    "    std = X.std(0)\n",
    "    Xnorm = (X - mean[None, :]) / std[None, :]\n",
    "    return Xnorm\n",
    "\n",
    "Xnorm = normalitzar(X)\n",
    "X_norm, y_norm = perform_split(Xnorm, y, split_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7882264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nL'atribut normalitzat amb MSE menor és\", labels[mse_norm.index(min(mse_norm))])\n",
    "chart_MSE(X_norm, y_norm, labels, \"normalitzat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63005b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 10**-12\n",
    "dif = [e - e_norm if abs(e - e_norm) > tol else 0 for e, e_norm in zip(mse, mse_norm)]\n",
    "a=chartMe(dif,rownames=labels,colnames=[\"Attribute\", \"Value\"], pre=\"Difference of\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_normal = calc_full(X_, y_)\n",
    "normal = calc_full(X_norm, y_norm)\n",
    "chartMe(content=[no_normal,normal],rownames=[\"Sense normalitzar\",\"Normalitzant\"],colnames=[\"\",\"MSE\",\"$R^2$\"],precision=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790a8a0",
   "metadata": {},
   "source": [
    "No hi ha cap canvi apreciable en cap de les mesures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f48765",
   "metadata": {},
   "source": [
    "5. Com millora la regressió quan es filtren aquells atributs de les mostres que no contenen informació?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a39280",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinfo = Xnorm[:,[1, 2, 3, 4, 5, 6, 7]]\n",
    "X_info, y_info = perform_split(Xinfo, y, split_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used = calc_full(X_, y_)\n",
    "only_info = calc_full(X_info, y_info)\n",
    "chartMe(content=[all_used,\n",
    "                 only_info],\n",
    "        rownames=[\"Amb tots els atributs\",\n",
    "                  \"Només amb l'informació útil\"],\n",
    "        colnames=[\"\",\"MSE\",\"$R^2$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a6f4f",
   "metadata": {},
   "source": [
    "Es pot veure una pujada (de l'ordre de $10^{-4}$, és a dir, insignificant) a l'MSE, i una baixada al $R^2$ de l'ordre de $10^{-2}$, és a dir, poc apreciable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e0f81",
   "metadata": {},
   "source": [
    "6. Si s'aplica un PCA, a quants components es redueix l'espai? Per què?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "XbestPCA = PCA(n_components='mle').fit_transform(Xnorm)\n",
    "X_bestPCA, y_bestPCA = perform_split(XbestPCA, y, split_info)\n",
    "\n",
    "print(\"Espai reduit a\", XbestPCA.shape[1], \"dimensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc016cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used = calc_full(X_, y_)\n",
    "only_info = calc_full(X_info, y_info)\n",
    "PCA_used = calc_full(X_bestPCA, y_bestPCA)\n",
    "\n",
    "chartMe(content=[all_used,\n",
    "                only_info,\n",
    "                PCA_used],\n",
    "       rownames=[\"Amb tots els atributs\",\n",
    "                \"Només els que contenen informacio util\",\n",
    "                \"Reduït utilitzant PCA\"],\n",
    "       colnames=[\"\",\"MSE\",\"$R^2$\"],\n",
    "       precision=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677b455",
   "metadata": {},
   "source": [
    "# Apartat (A): El descens del gradient  \n",
    "\n",
    "1. Com influeixen tots els paràmetres en el procés de descens? Quins valors de learning rate convergeixen més ràpid a la solució òptima? Com influeix la inicialització del model en el resultat final? \n",
    "\n",
    "2. Quines funcions polinomials (de diferent grau, de diferents combinacions d'atributs, ...) heu escollit per ser apreses amb el vostre descens del gradient? quina ha donat el millor resultat (en error i rapidesa en convergència)?\n",
    "\n",
    "3. Utilitzeu el regularitzador en la fòrmula de funció de cost i descens del gradient i proveu polinomis de diferent grau. Com afecta el valor del regularitzador?\n",
    "\n",
    "3. Quina diferència (quantitativa i qualitativa) hi ha entre el vostre regressor i el de la llibreria ?\n",
    "\n",
    "4. Té sentit el model (polinomial) trobat quan es visualitza sobre les dades? \n",
    "\n",
    "5. Ajuda la visualització a identificar aquelles mostres per a les que el regressor obté els pitjors resultats de predicció? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f474961",
   "metadata": {},
   "source": [
    "$$J(w) = \\frac{1}{2m} \\left[ \\sum^m_{i=1}(f(x^{i}; w) - y^{i})^2 + \\lambda\\sum_{j=1}^{n}(w_{j}^2) \\right]$$\n",
    "\n",
    "$$w_0 = w_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot 1$$\n",
    "$$w_j = w_j - \\alpha \\left[\\frac{1}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot x_{j}^{i} - \\frac{\\lambda}{m}w_{j} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc143a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "class Regressor(object):\n",
    "    def __init__(self, alpha=0.3, regularitzador=0.0, initial_bias=None, initial_weight=None):\n",
    "        if initial_bias == None:\n",
    "            self.w0 = np.random.rand()\n",
    "        else:\n",
    "            self.w0 = initial_bias\n",
    "        if initial_weight == None:\n",
    "            self.wj = np.array([])\n",
    "        else:\n",
    "            self.wj = initial_weight\n",
    "        self.alpha = alpha\n",
    "        self.regularitzador = regularitzador\n",
    "        self.loaded = False\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.w0 + x.dot(self.wj)\n",
    "    \n",
    "    def __cost(self, hy, y):\n",
    "        return (np.square(hy - y).sum() + self.regularitzador * np.square(self.wj).sum()) / (2 * y.size)\n",
    "    \n",
    "    def __update(self, hy, y):\n",
    "        self.w0 -= self.alpha * (hy - y).sum() / y.size\n",
    "        self.wj -= self.alpha / y.size * ((hy - y).dot(self.X) - self.regularitzador * self.wj)\n",
    "    \n",
    "    def train(self, max_iter, epsilon=0.000001):\n",
    "        if not self.loaded:\n",
    "            raise ValueError(\"No dataset loaded for training\")\n",
    "        hy = self.predict(self.X)\n",
    "        J = self.__cost(hy, self.y)\n",
    "        for i in range(max_iter):\n",
    "            self.__update(hy, self.y)\n",
    "            hy = self.predict(self.X)\n",
    "            Jnew = self.__cost(hy, self.y)\n",
    "            delta = abs(Jnew - J)\n",
    "            if delta < epsilon:\n",
    "                break\n",
    "            J = Jnew\n",
    "    \n",
    "    def load(self, Xtrain, ytrain):\n",
    "        self.X = Xtrain\n",
    "        self.y = ytrain\n",
    "        if self.wj.size != self.X.shape[1]:\n",
    "            self.wj = np.random.rand(self.X.shape[1])\n",
    "        self.loaded = True\n",
    "\n",
    "def make_polinomial(X, degree=1):\n",
    "    poli = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    return poli.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar Polinomi exemple\n",
    "make_polinomial(Xnorm[:,[5]], degree=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXEMPLES ###\n",
    "\n",
    "# Regressor implementat per X_5 i X_5^2\n",
    "X_poli1, y_poli1 = perform_split(make_polinomial(Xnorm[:,[5]], degree=2), y, split_info)\n",
    "r = Regressor(alpha=.05, regularitzador=10)\n",
    "r.load(X_poli1[0], y_poli1[0])\n",
    "r.train(4000, epsilon=0.0001)\n",
    "print(MSE(r.predict(X_poli1[0]), y_poli1[0]))\n",
    "print(MSE(r.predict(X_poli1[1]), y_poli1[1]))\n",
    "\n",
    "# Regressor implementat per X_5, X_5^2, X_5^3 i X_5^4\n",
    "X_poli2, y_poli2 = perform_split(make_polinomial(Xnorm[:,[5]], degree=4), y, split_info)\n",
    "r = Regressor(alpha=.01, regularitzador=0)\n",
    "r.load(X_poli2[0], y_poli2[0])\n",
    "r.train(4000, epsilon=0)\n",
    "print(MSE(r.predict(X_poli2[0]), y_poli2[0]))\n",
    "print(MSE(r.predict(X_poli2[1]), y_poli2[1]))\n",
    "\n",
    "# Regressor importat per X_5 i X_5^2\n",
    "r = regression(X_poli1[0], y_poli1[0])\n",
    "print(MSE(r.predict(X_poli1[0]), y_poli1[0]))\n",
    "print(MSE(r.predict(X_poli1[1]), y_poli1[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
